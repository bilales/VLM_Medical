Traceback (most recent call last):
  File "C:\Users\bilal\Documents\VLM_Medical\train.py", line 68, in <module>
    model = AutoModelForCausalLM.from_pretrained(
  File "C:\Users\bilal\Documents\VLM_Medical\.venv\lib\site-packages\transformers\models\auto\auto_factory.py", line 564, in from_pretrained
    return model_class.from_pretrained(
  File "C:\Users\bilal\Documents\VLM_Medical\.venv\lib\site-packages\transformers\modeling_utils.py", line 309, in _wrapper
    return func(*args, **kwargs)
  File "C:\Users\bilal\Documents\VLM_Medical\.venv\lib\site-packages\transformers\modeling_utils.py", line 4390, in from_pretrained
    hf_quantizer.validate_environment(
  File "C:\Users\bilal\Documents\VLM_Medical\.venv\lib\site-packages\transformers\quantizers\quantizer_bnb_4bit.py", line 76, in validate_environment
    raise ImportError(
ImportError: Using `bitsandbytes` 4-bit quantization requires the latest version of bitsandbytes: `pip install -U bitsandbytes`
